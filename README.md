# Building Data Warehouse and ETL pinelines with Airflow Project

### Set up Environments
1. Airflow with Docker
   - Download docker-compose.yaml file.
   - Create folder: mkdir -p ./dags, ./logs, ./plugins, ./config
   - Init docker with airflow: docker compose up airflow-init
   - Running Airflow: docker compose up -d
   - Check docker running: docker ps

# Online Retail Data Pipeline Project

## ğŸ“Š Project Overview
This project focuses on building a complete **data pipeline** for the [Online Retail dataset](https://www.kaggle.com/datasets/tunguz/online-retail?resource=download). The goal is to extract, transform, and load (ETL) the dataset into a PostgreSQL data warehouse and visualize the insights using Python & Power BI. Apache Airflow is used to orchestrate and automate the data pipeline.

## ğŸ”¬ Architecture
![Architecture](./images/architecture.png)

## ğŸ“ Data Modeling
![Data Modeling](./images/data_modeling.png)

## ğŸ› ï¸ Technology Stack
- **Apache Airflow**: Workflow orchestration for managing ETL processes.
- **Python**: Data extraction, transformation, loading and analysis.
- **PostgreSQL**: Data warehouse for storing processed data.
- **Power BI**: Data visualization and reporting.

## ğŸ“Š Dataset Information
- **Source**: [Online Retail Dataset](https://www.kaggle.com/datasets/tunguz/online-retail?resource=download)
- **Description**: Transactions from a UK-based online retailer between 2010-2011.
- **Key Columns**:
    - `InvoiceNo`: Unique identifier for each transaction
    - `StockCode`: Product code
    - `Description`: Product name
    - `Quantity`: Number of products purchased
    - `InvoiceDate`: Date of purchase
    - `UnitPrice`: Price per product
    - `CustomerID`: Unique customer identifier
    - `Country`: Customer's country

## ğŸ“Œ Project Workflow
- Airflow ETL pineline
![ETL](./images/airflow_pineline.png)
1. **Extract**: Download and extract data from the Kaggle dataset.
2. **Transform**: Clean and preprocess the data (e.g., handling missing values, data type conversion).
3. **Load**: Load the processed data into a PostgreSQL data warehouse.
4. **Visualize**: Build interactive dashboards using Power BI & Python.

## ğŸ“ Project Structure
```
â”œâ”€â”€ analysis/            # Data analysis with Python
â”‚    â””â”€â”€ data_analysis.ipynb
â”œâ”€â”€ dags/                # Airflow DAGs
â”‚    â”œâ”€â”€ data/raw/       # Raw data
â”‚    â”‚    â””â”€â”€ Online_Retail.csv
â”‚    â””â”€â”€ ETL_dag.py
â”œâ”€â”€ dashboard/           # Power BI dashboard
â”‚    â””â”€â”€ dashboard_powerbi.pbix
â”œâ”€â”€ images/              # Project images
â”œâ”€â”€ sql_scripts/         # SQL scripts for analysis, report
â”‚    â”œâ”€â”€ AnalysisQueryScripts.sql
â”‚    â””â”€â”€ CustomerReportScripts.sql
â”œâ”€â”€ docker_compose.yaml  # Docker config
â””â”€â”€ README.md            # Project documentation
```

## ğŸ“Š Data analysis with Python
- Monthly Sales Trend
  ![MonthlySalesTrend](./images/MonthlySalesTrend.png)

- Busiest Days of the Week
  ![BusitetDaysOfTheWeek](./images/BusitetDaysOfTheWeek.png)

- Top-Selling Products By Country
  ![Top-SellingProducts](./images/Top-SellingProductsByCountry.png)

- RFM Analysis
  ![RFMSegmentsChart](./images/RFMSegments.png)
  ![RFMSegmentsPercentage](./images/RFMSegmentsPercentage.png)

## ğŸ“Š Power BI Dashboard
- Sales Dashboard
  ![SalesDashboard](./images/SalesDashboard.png)

- Customer Dashboard
  ![CustomerDashboard](./images/CustomerDashboard.png)
- Import the processed data from PostgreSQL into Power BI.

## ğŸ“ Contact
For questions or suggestions, reach out via nguyenquangphuc412@gmail.com